{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"evaluation_notebook_OD.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1uHVP0A38kg2Wv9K4mJJmKybqAuIMrH3R","authorship_tag":"ABX9TyOccmqvPpmS6G+Q7hJEonW5"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"32H93PkbogfH","executionInfo":{"status":"ok","timestamp":1632031504668,"user_tz":-420,"elapsed":349,"user":{"displayName":"Afkaar Arrachmandhika Muhammad Lanang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11774006176532521439"}},"outputId":"61399a3c-7c98-443e-af20-b47eb0550b02"},"source":["!nvidia-smi"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Sep 19 06:05:04 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   42C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"4Rq5Bx9QSmZb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1632031587887,"user_tz":-420,"elapsed":81765,"user":{"displayName":"Afkaar Arrachmandhika Muhammad Lanang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11774006176532521439"}},"outputId":"8d9bde5d-4e4e-4025-81c9-35307ff35323"},"source":["!git clone https://github.com/tensorflow/models.git\n","%cd models/research/\n","# Compile protos.\n","!protoc object_detection/protos/*.proto --python_out=.\n","# Install TensorFlow Object Detection API.\n","!cp object_detection/packages/tf2/setup.py .\n","!python -m pip install --use-feature=2020-resolver .\n","!python object_detection/builders/model_builder_tf2_test.py"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'models'...\n","remote: Enumerating objects: 62926, done.\u001b[K\n","remote: Counting objects: 100% (188/188), done.\u001b[K\n","remote: Compressing objects: 100% (125/125), done.\u001b[K\n","remote: Total 62926 (delta 65), reused 182 (delta 63), pack-reused 62738\u001b[K\n","Receiving objects: 100% (62926/62926), 574.58 MiB | 36.23 MiB/s, done.\n","Resolving deltas: 100% (43877/43877), done.\n","/content/models/research\n","\u001b[33mWARNING: --use-feature=2020-resolver no longer has any effect, since it is now the default dependency resolver in pip. This will become an error in pip 21.0.\u001b[0m\n","Processing /content/models/research\n","\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n","   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n","Collecting avro-python3\n","  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n","Collecting apache-beam\n","  Downloading apache_beam-2.32.0-cp37-cp37m-manylinux2010_x86_64.whl (9.8 MB)\n","\u001b[K     |████████████████████████████████| 9.8 MB 8.5 MB/s \n","\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.2.6)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n","Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.24)\n","Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n","Collecting tf-slim\n","  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n","\u001b[K     |████████████████████████████████| 352 kB 72.0 MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n","Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.2)\n","Collecting lvis\n","  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.4.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.1.5)\n","Collecting tf-models-official>=2.5.1\n","  Downloading tf_models_official-2.6.0-py2.py3-none-any.whl (1.8 MB)\n","\u001b[K     |████████████████████████████████| 1.8 MB 62.9 MB/s \n","\u001b[?25hCollecting pyyaml>=5.1\n","  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n","\u001b[K     |████████████████████████████████| 636 kB 72.7 MB/s \n","\u001b[?25hCollecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[K     |████████████████████████████████| 43 kB 2.5 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.0.1)\n","Requirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n","Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.8)\n","Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n","Collecting py-cpuinfo>=3.3.0\n","  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n","\u001b[K     |████████████████████████████████| 99 kB 12.3 MB/s \n","\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Collecting opencv-python-headless\n","  Downloading opencv_python_headless-4.5.3.56-cp37-cp37m-manylinux2014_x86_64.whl (37.1 MB)\n","\u001b[K     |████████████████████████████████| 37.1 MB 88 kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15.4 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.19.5)\n","Collecting sacrebleu\n","  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n","\u001b[K     |████████████████████████████████| 90 kB 12.5 MB/s \n","\u001b[?25hRequirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n","Collecting tensorflow-model-optimization>=0.4.1\n","  Downloading tensorflow_model_optimization-0.6.0-py2.py3-none-any.whl (211 kB)\n","\u001b[K     |████████████████████████████████| 211 kB 68.0 MB/s \n","\u001b[?25hCollecting sentencepiece\n","  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n","\u001b[K     |████████████████████████████████| 1.2 MB 29.8 MB/s \n","\u001b[?25hCollecting tensorflow-addons\n","  Downloading tensorflow_addons-0.14.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n","\u001b[K     |████████████████████████████████| 1.1 MB 73.4 MB/s \n","\u001b[?25hCollecting tensorflow-text>=2.5.0\n","  Downloading tensorflow_text-2.6.0-cp37-cp37m-manylinux1_x86_64.whl (4.4 MB)\n","\u001b[K     |████████████████████████████████| 4.4 MB 24.6 MB/s \n","\u001b[?25hRequirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n","Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n","Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n","Requirement already satisfied: google-auth>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n","Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.26.3)\n","Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n","Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.0)\n","Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n","Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2018.9)\n","Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.53.0)\n","Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.2)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.7.2)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2021.5.30)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n","Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (5.0.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.62.2)\n","Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.4.7)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n","Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n","Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12)\n","Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n","Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.7.4.3)\n","Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n","Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.0)\n","Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n","Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n","Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.40.0)\n","Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (5.0)\n","Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n","Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (2.6.0)\n","Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n","Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.0)\n","Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.12.1)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.4)\n","Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.0)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (4.8.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.1)\n","Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.6)\n","Collecting requests<3.0.0dev,>=2.18.0\n","  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n","\u001b[K     |████████████████████████████████| 62 kB 1.1 MB/s \n","\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n","Collecting dill<0.3.2,>=0.3.1.1\n","  Downloading dill-0.3.1.1.tar.gz (151 kB)\n","\u001b[K     |████████████████████████████████| 151 kB 79.5 MB/s \n","\u001b[?25hRequirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.12.0)\n","Collecting avro-python3\n","  Downloading avro-python3-1.9.2.1.tar.gz (37 kB)\n","Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n","Collecting future<1.0.0,>=0.18.2\n","  Downloading future-0.18.2.tar.gz (829 kB)\n","\u001b[K     |████████████████████████████████| 829 kB 54.2 MB/s \n","\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n","  Downloading hdfs-2.6.0-py3-none-any.whl (33 kB)\n","Collecting orjson<4.0\n","  Downloading orjson-3.6.3-cp37-cp37m-manylinux_2_24_x86_64.whl (234 kB)\n","\u001b[K     |████████████████████████████████| 234 kB 72.8 MB/s \n","\u001b[?25hRequirement already satisfied: pyarrow<5.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n","Collecting fastavro<2,>=0.21.4\n","  Downloading fastavro-1.4.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n","\u001b[K     |████████████████████████████████| 2.3 MB 54.2 MB/s \n","\u001b[?25hRequirement already satisfied: docopt in /usr/local/lib/python3.7/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.0.5)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.0->tf-models-official>=2.5.1->object-detection==0.1) (3.5.0)\n","Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.3.2)\n","Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.10.0)\n","Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.1.2.30)\n","Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (0.8.9)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu->tf-models-official>=2.5.1->object-detection==0.1) (2019.12.20)\n","Collecting colorama\n","  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n","Collecting portalocker\n","  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (0.22.2.post1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n","Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n","Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.2.2)\n","Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n","Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (21.2.0)\n","Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n","Building wheels for collected packages: object-detection, py-cpuinfo, avro-python3, dill, future, seqeval\n","  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1665422 sha256=504aa4f87b37ea9656393500453ff32e8d66d532a15858efd8baf09fa3032fc2\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-7pk5hysn/wheels/fa/a4/d2/e9a5057e414fd46c8e543d2706cd836d64e1fcd9eccceb2329\n","  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22258 sha256=9142c7113e911b5ba757a870276ae5b2ee98772a54b78d5858abd2c737d05985\n","  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n","  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for avro-python3: filename=avro_python3-1.9.2.1-py3-none-any.whl size=43512 sha256=9add148b27d3df06b7c455e9d198456128cb9fc82b13d1e4bac276607119c14b\n","  Stored in directory: /root/.cache/pip/wheels/bc/49/5f/fdb5b9d85055c478213e0158ac122b596816149a02d82e0ab1\n","  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78546 sha256=a94f7fc5d0bcb9dd1f21d49d843aa0dbd9920365700176137ca0f3f9fe946456\n","  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n","  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for future: filename=future-0.18.2-py3-none-any.whl size=491070 sha256=e1470c033b6f929188174e7360cf21c5bd38b38eb47930177c694e1f214c95a3\n","  Stored in directory: /root/.cache/pip/wheels/56/b0/fe/4410d17b32f1f0c3cf54cdfb2bc04d7b4b8f4ae377e2229ba0\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16181 sha256=c12ac6ecd3cd79f0e7f0fe337b4958c56d98fd54cb3ff134bfd9b15367fc6965\n","  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n","Successfully built object-detection py-cpuinfo avro-python3 dill future seqeval\n","Installing collected packages: requests, portalocker, future, dill, colorama, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, py-cpuinfo, orjson, opencv-python-headless, hdfs, fastavro, avro-python3, tf-models-official, lvis, apache-beam, object-detection\n","  Attempting uninstall: requests\n","    Found existing installation: requests 2.23.0\n","    Uninstalling requests-2.23.0:\n","      Successfully uninstalled requests-2.23.0\n","  Attempting uninstall: future\n","    Found existing installation: future 0.16.0\n","    Uninstalling future-0.16.0:\n","      Successfully uninstalled future-0.16.0\n","  Attempting uninstall: dill\n","    Found existing installation: dill 0.3.4\n","    Uninstalling dill-0.3.4:\n","      Successfully uninstalled dill-0.3.4\n","  Attempting uninstall: pyyaml\n","    Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","multiprocess 0.70.12.2 requires dill>=0.3.4, but you have dill 0.3.1.1 which is incompatible.\n","google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n","datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n","Successfully installed apache-beam-2.32.0 avro-python3-1.9.2.1 colorama-0.4.4 dill-0.3.1.1 fastavro-1.4.4 future-0.18.2 hdfs-2.6.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.3.56 orjson-3.6.3 portalocker-2.3.2 py-cpuinfo-8.0.0 pyyaml-5.4.1 requests-2.26.0 sacrebleu-2.0.0 sentencepiece-0.1.96 seqeval-1.2.2 tensorflow-addons-0.14.0 tensorflow-model-optimization-0.6.0 tensorflow-text-2.6.0 tf-models-official-2.6.0 tf-slim-1.1.0\n","2021-09-19 06:06:00.203329: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:06:00.535533: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:06:00.536243: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","Running tests under Python 3.7.12: /usr/bin/python3\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","2021-09-19 06:06:00.556830: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-09-19 06:06:00.557088: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:06:00.557830: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:06:00.558526: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:06:03.323367: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:06:03.324121: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:06:03.324802: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:06:03.325529: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-09-19 06:06:03.325597: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13839 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","W0919 06:06:03.564037 140436789159808 model_builder.py:1091] Building experimental DeepMAC meta-arch. Some features may be omitted.\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.36s\n","I0919 06:06:03.902302 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 3.36s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.47s\n","I0919 06:06:04.376741 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.47s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.26s\n","I0919 06:06:04.632381 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.26s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.24s\n","I0919 06:06:04.870998 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.24s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n","[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.63s\n","I0919 06:06:06.499471 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.63s\n","[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n","[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","I0919 06:06:06.500404 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n","I0919 06:06:06.521210 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n","I0919 06:06:06.535284 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n","I0919 06:06:06.549366 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.01s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n","I0919 06:06:06.641983 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n","I0919 06:06:06.733708 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n","I0919 06:06:06.833164 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n","I0919 06:06:06.924747 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n","[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n","I0919 06:06:07.017474 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.09s\n","[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","I0919 06:06:07.052082 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.03s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","I0919 06:06:07.339830 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n","I0919 06:06:07.339989 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n","I0919 06:06:07.340070 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n","I0919 06:06:07.342172 140436789159808 efficientnet_model.py:147] round_filter input=32 output=32\n","I0919 06:06:07.357226 140436789159808 efficientnet_model.py:147] round_filter input=32 output=32\n","I0919 06:06:07.357351 140436789159808 efficientnet_model.py:147] round_filter input=16 output=16\n","I0919 06:06:07.409255 140436789159808 efficientnet_model.py:147] round_filter input=16 output=16\n","I0919 06:06:07.409394 140436789159808 efficientnet_model.py:147] round_filter input=24 output=24\n","I0919 06:06:07.543260 140436789159808 efficientnet_model.py:147] round_filter input=24 output=24\n","I0919 06:06:07.543401 140436789159808 efficientnet_model.py:147] round_filter input=40 output=40\n","I0919 06:06:07.677669 140436789159808 efficientnet_model.py:147] round_filter input=40 output=40\n","I0919 06:06:07.677817 140436789159808 efficientnet_model.py:147] round_filter input=80 output=80\n","I0919 06:06:07.885823 140436789159808 efficientnet_model.py:147] round_filter input=80 output=80\n","I0919 06:06:07.885992 140436789159808 efficientnet_model.py:147] round_filter input=112 output=112\n","I0919 06:06:08.093791 140436789159808 efficientnet_model.py:147] round_filter input=112 output=112\n","I0919 06:06:08.093954 140436789159808 efficientnet_model.py:147] round_filter input=192 output=192\n","I0919 06:06:08.380738 140436789159808 efficientnet_model.py:147] round_filter input=192 output=192\n","I0919 06:06:08.380915 140436789159808 efficientnet_model.py:147] round_filter input=320 output=320\n","I0919 06:06:08.446605 140436789159808 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0919 06:06:08.473561 140436789159808 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0919 06:06:08.527306 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b1\n","I0919 06:06:08.527446 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 88\n","I0919 06:06:08.527537 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 4\n","I0919 06:06:08.529050 140436789159808 efficientnet_model.py:147] round_filter input=32 output=32\n","I0919 06:06:08.542689 140436789159808 efficientnet_model.py:147] round_filter input=32 output=32\n","I0919 06:06:08.542802 140436789159808 efficientnet_model.py:147] round_filter input=16 output=16\n","I0919 06:06:08.654635 140436789159808 efficientnet_model.py:147] round_filter input=16 output=16\n","I0919 06:06:08.654763 140436789159808 efficientnet_model.py:147] round_filter input=24 output=24\n","I0919 06:06:08.864151 140436789159808 efficientnet_model.py:147] round_filter input=24 output=24\n","I0919 06:06:08.864318 140436789159808 efficientnet_model.py:147] round_filter input=40 output=40\n","I0919 06:06:09.068746 140436789159808 efficientnet_model.py:147] round_filter input=40 output=40\n","I0919 06:06:09.068909 140436789159808 efficientnet_model.py:147] round_filter input=80 output=80\n","I0919 06:06:09.335719 140436789159808 efficientnet_model.py:147] round_filter input=80 output=80\n","I0919 06:06:09.335885 140436789159808 efficientnet_model.py:147] round_filter input=112 output=112\n","I0919 06:06:09.606011 140436789159808 efficientnet_model.py:147] round_filter input=112 output=112\n","I0919 06:06:09.606180 140436789159808 efficientnet_model.py:147] round_filter input=192 output=192\n","I0919 06:06:09.944094 140436789159808 efficientnet_model.py:147] round_filter input=192 output=192\n","I0919 06:06:09.944258 140436789159808 efficientnet_model.py:147] round_filter input=320 output=320\n","I0919 06:06:10.075757 140436789159808 efficientnet_model.py:147] round_filter input=1280 output=1280\n","I0919 06:06:10.102453 140436789159808 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0919 06:06:10.272866 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b2\n","I0919 06:06:10.273022 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 112\n","I0919 06:06:10.273101 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 5\n","I0919 06:06:10.274609 140436789159808 efficientnet_model.py:147] round_filter input=32 output=32\n","I0919 06:06:10.288139 140436789159808 efficientnet_model.py:147] round_filter input=32 output=32\n","I0919 06:06:10.288266 140436789159808 efficientnet_model.py:147] round_filter input=16 output=16\n","I0919 06:06:10.393366 140436789159808 efficientnet_model.py:147] round_filter input=16 output=16\n","I0919 06:06:10.393512 140436789159808 efficientnet_model.py:147] round_filter input=24 output=24\n","I0919 06:06:10.596595 140436789159808 efficientnet_model.py:147] round_filter input=24 output=24\n","I0919 06:06:10.596749 140436789159808 efficientnet_model.py:147] round_filter input=40 output=48\n","I0919 06:06:10.798380 140436789159808 efficientnet_model.py:147] round_filter input=40 output=48\n","I0919 06:06:10.798557 140436789159808 efficientnet_model.py:147] round_filter input=80 output=88\n","I0919 06:06:11.073308 140436789159808 efficientnet_model.py:147] round_filter input=80 output=88\n","I0919 06:06:11.073488 140436789159808 efficientnet_model.py:147] round_filter input=112 output=120\n","I0919 06:06:11.344366 140436789159808 efficientnet_model.py:147] round_filter input=112 output=120\n","I0919 06:06:11.344547 140436789159808 efficientnet_model.py:147] round_filter input=192 output=208\n","I0919 06:06:11.681764 140436789159808 efficientnet_model.py:147] round_filter input=192 output=208\n","I0919 06:06:11.681965 140436789159808 efficientnet_model.py:147] round_filter input=320 output=352\n","I0919 06:06:11.815384 140436789159808 efficientnet_model.py:147] round_filter input=1280 output=1408\n","I0919 06:06:11.840859 140436789159808 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0919 06:06:11.904838 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b3\n","I0919 06:06:11.904979 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 160\n","I0919 06:06:11.905047 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 6\n","I0919 06:06:11.906556 140436789159808 efficientnet_model.py:147] round_filter input=32 output=40\n","I0919 06:06:11.921087 140436789159808 efficientnet_model.py:147] round_filter input=32 output=40\n","I0919 06:06:11.921206 140436789159808 efficientnet_model.py:147] round_filter input=16 output=24\n","I0919 06:06:12.031718 140436789159808 efficientnet_model.py:147] round_filter input=16 output=24\n","I0919 06:06:12.031866 140436789159808 efficientnet_model.py:147] round_filter input=24 output=32\n","I0919 06:06:12.229969 140436789159808 efficientnet_model.py:147] round_filter input=24 output=32\n","I0919 06:06:12.230116 140436789159808 efficientnet_model.py:147] round_filter input=40 output=48\n","I0919 06:06:12.434115 140436789159808 efficientnet_model.py:147] round_filter input=40 output=48\n","I0919 06:06:12.434271 140436789159808 efficientnet_model.py:147] round_filter input=80 output=96\n","I0919 06:06:12.770912 140436789159808 efficientnet_model.py:147] round_filter input=80 output=96\n","I0919 06:06:12.771078 140436789159808 efficientnet_model.py:147] round_filter input=112 output=136\n","I0919 06:06:13.124592 140436789159808 efficientnet_model.py:147] round_filter input=112 output=136\n","I0919 06:06:13.124775 140436789159808 efficientnet_model.py:147] round_filter input=192 output=232\n","I0919 06:06:13.526542 140436789159808 efficientnet_model.py:147] round_filter input=192 output=232\n","I0919 06:06:13.526711 140436789159808 efficientnet_model.py:147] round_filter input=320 output=384\n","I0919 06:06:13.662295 140436789159808 efficientnet_model.py:147] round_filter input=1280 output=1536\n","I0919 06:06:13.687308 140436789159808 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0919 06:06:13.948873 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b4\n","I0919 06:06:13.949042 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 224\n","I0919 06:06:13.949116 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n","I0919 06:06:13.950763 140436789159808 efficientnet_model.py:147] round_filter input=32 output=48\n","I0919 06:06:13.966265 140436789159808 efficientnet_model.py:147] round_filter input=32 output=48\n","I0919 06:06:13.966378 140436789159808 efficientnet_model.py:147] round_filter input=16 output=24\n","I0919 06:06:14.078852 140436789159808 efficientnet_model.py:147] round_filter input=16 output=24\n","I0919 06:06:14.078985 140436789159808 efficientnet_model.py:147] round_filter input=24 output=32\n","I0919 06:06:14.353258 140436789159808 efficientnet_model.py:147] round_filter input=24 output=32\n","I0919 06:06:14.353414 140436789159808 efficientnet_model.py:147] round_filter input=40 output=56\n","I0919 06:06:14.622432 140436789159808 efficientnet_model.py:147] round_filter input=40 output=56\n","I0919 06:06:14.622637 140436789159808 efficientnet_model.py:147] round_filter input=80 output=112\n","I0919 06:06:15.030673 140436789159808 efficientnet_model.py:147] round_filter input=80 output=112\n","I0919 06:06:15.030848 140436789159808 efficientnet_model.py:147] round_filter input=112 output=160\n","I0919 06:06:15.434860 140436789159808 efficientnet_model.py:147] round_filter input=112 output=160\n","I0919 06:06:15.435024 140436789159808 efficientnet_model.py:147] round_filter input=192 output=272\n","I0919 06:06:15.973292 140436789159808 efficientnet_model.py:147] round_filter input=192 output=272\n","I0919 06:06:15.973470 140436789159808 efficientnet_model.py:147] round_filter input=320 output=448\n","I0919 06:06:16.106922 140436789159808 efficientnet_model.py:147] round_filter input=1280 output=1792\n","I0919 06:06:16.133057 140436789159808 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0919 06:06:16.209973 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b5\n","I0919 06:06:16.210110 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 288\n","I0919 06:06:16.210181 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 7\n","I0919 06:06:16.211664 140436789159808 efficientnet_model.py:147] round_filter input=32 output=48\n","I0919 06:06:16.224646 140436789159808 efficientnet_model.py:147] round_filter input=32 output=48\n","I0919 06:06:16.224746 140436789159808 efficientnet_model.py:147] round_filter input=16 output=24\n","I0919 06:06:16.385720 140436789159808 efficientnet_model.py:147] round_filter input=16 output=24\n","I0919 06:06:16.385869 140436789159808 efficientnet_model.py:147] round_filter input=24 output=40\n","I0919 06:06:16.728332 140436789159808 efficientnet_model.py:147] round_filter input=24 output=40\n","I0919 06:06:16.728509 140436789159808 efficientnet_model.py:147] round_filter input=40 output=64\n","I0919 06:06:17.075218 140436789159808 efficientnet_model.py:147] round_filter input=40 output=64\n","I0919 06:06:17.075392 140436789159808 efficientnet_model.py:147] round_filter input=80 output=128\n","I0919 06:06:17.535300 140436789159808 efficientnet_model.py:147] round_filter input=80 output=128\n","I0919 06:06:17.535471 140436789159808 efficientnet_model.py:147] round_filter input=112 output=176\n","I0919 06:06:18.188230 140436789159808 efficientnet_model.py:147] round_filter input=112 output=176\n","I0919 06:06:18.188404 140436789159808 efficientnet_model.py:147] round_filter input=192 output=304\n","I0919 06:06:18.773507 140436789159808 efficientnet_model.py:147] round_filter input=192 output=304\n","I0919 06:06:18.773670 140436789159808 efficientnet_model.py:147] round_filter input=320 output=512\n","I0919 06:06:18.972272 140436789159808 efficientnet_model.py:147] round_filter input=1280 output=2048\n","I0919 06:06:19.007519 140436789159808 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0919 06:06:19.095356 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b6\n","I0919 06:06:19.095509 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n","I0919 06:06:19.095578 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n","I0919 06:06:19.097176 140436789159808 efficientnet_model.py:147] round_filter input=32 output=56\n","I0919 06:06:19.110597 140436789159808 efficientnet_model.py:147] round_filter input=32 output=56\n","I0919 06:06:19.110704 140436789159808 efficientnet_model.py:147] round_filter input=16 output=32\n","I0919 06:06:19.265362 140436789159808 efficientnet_model.py:147] round_filter input=16 output=32\n","I0919 06:06:19.265499 140436789159808 efficientnet_model.py:147] round_filter input=24 output=40\n","I0919 06:06:19.656228 140436789159808 efficientnet_model.py:147] round_filter input=24 output=40\n","I0919 06:06:19.656397 140436789159808 efficientnet_model.py:147] round_filter input=40 output=72\n","I0919 06:06:20.072447 140436789159808 efficientnet_model.py:147] round_filter input=40 output=72\n","I0919 06:06:20.072613 140436789159808 efficientnet_model.py:147] round_filter input=80 output=144\n","I0919 06:06:20.594911 140436789159808 efficientnet_model.py:147] round_filter input=80 output=144\n","I0919 06:06:20.595079 140436789159808 efficientnet_model.py:147] round_filter input=112 output=200\n","I0919 06:06:21.136239 140436789159808 efficientnet_model.py:147] round_filter input=112 output=200\n","I0919 06:06:21.136429 140436789159808 efficientnet_model.py:147] round_filter input=192 output=344\n","I0919 06:06:22.056241 140436789159808 efficientnet_model.py:147] round_filter input=192 output=344\n","I0919 06:06:22.056468 140436789159808 efficientnet_model.py:147] round_filter input=320 output=576\n","I0919 06:06:22.249866 140436789159808 efficientnet_model.py:147] round_filter input=1280 output=2304\n","I0919 06:06:22.274070 140436789159808 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","I0919 06:06:22.383662 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b7\n","I0919 06:06:22.383807 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 384\n","I0919 06:06:22.383878 140436789159808 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 8\n","I0919 06:06:22.385588 140436789159808 efficientnet_model.py:147] round_filter input=32 output=64\n","I0919 06:06:22.399964 140436789159808 efficientnet_model.py:147] round_filter input=32 output=64\n","I0919 06:06:22.400089 140436789159808 efficientnet_model.py:147] round_filter input=16 output=32\n","I0919 06:06:22.618297 140436789159808 efficientnet_model.py:147] round_filter input=16 output=32\n","I0919 06:06:22.618463 140436789159808 efficientnet_model.py:147] round_filter input=24 output=48\n","I0919 06:06:23.083242 140436789159808 efficientnet_model.py:147] round_filter input=24 output=48\n","I0919 06:06:23.083514 140436789159808 efficientnet_model.py:147] round_filter input=40 output=80\n","I0919 06:06:23.546759 140436789159808 efficientnet_model.py:147] round_filter input=40 output=80\n","I0919 06:06:23.546929 140436789159808 efficientnet_model.py:147] round_filter input=80 output=160\n","I0919 06:06:24.212463 140436789159808 efficientnet_model.py:147] round_filter input=80 output=160\n","I0919 06:06:24.212628 140436789159808 efficientnet_model.py:147] round_filter input=112 output=224\n","I0919 06:06:24.879158 140436789159808 efficientnet_model.py:147] round_filter input=112 output=224\n","I0919 06:06:24.879344 140436789159808 efficientnet_model.py:147] round_filter input=192 output=384\n","I0919 06:06:25.738479 140436789159808 efficientnet_model.py:147] round_filter input=192 output=384\n","I0919 06:06:25.738643 140436789159808 efficientnet_model.py:147] round_filter input=320 output=640\n","I0919 06:06:26.238213 140436789159808 efficientnet_model.py:147] round_filter input=1280 output=2560\n","I0919 06:06:26.263441 140436789159808 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 19.33s\n","I0919 06:06:26.380787 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 19.33s\n","[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","I0919 06:06:26.387631 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","I0919 06:06:26.389270 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","I0919 06:06:26.389771 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n","[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","I0919 06:06:26.391239 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n","[ RUN      ] ModelBuilderTF2Test.test_session\n","[  SKIPPED ] ModelBuilderTF2Test.test_session\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","I0919 06:06:26.392665 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","I0919 06:06:26.393112 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n","[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","I0919 06:06:26.394093 140436789159808 test_util.py:2189] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n","[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n","----------------------------------------------------------------------\n","Ran 24 tests in 25.854s\n","\n","OK (skipped=1)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"07QU4pWmcgrX","executionInfo":{"status":"ok","timestamp":1632031610273,"user_tz":-420,"elapsed":328,"user":{"displayName":"Afkaar Arrachmandhika Muhammad Lanang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11774006176532521439"}},"outputId":"085acc12-a168-4fa6-e485-c301bbb713e0"},"source":["# Jumlah traning steps, 1000 akan training dengan sangat cepat, tetapi lebih banyak steps akan meningkatkan akurasi.\n","num_steps = 10000  # 200000 steps jika ingin meningkatkan lebih baik\n","\n","# Jumlah evaluation steps.\n","num_eval_steps = 50 \n","\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2_fpn': {\n","        'model_name': 'ssd_mobilenet_v2_fpnlite_640x640_coco17',\n","        'pipeline_file': 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config',\n","        'batch_size': 16,\n","        'checkpoint_path' : '/content/drive/MyDrive/colabData/SSD_MobileNet/checkpoint/ckpt-0'\n","    },\n","    'faster_rcnn_resnet152_v1': {\n","        'model_name': 'faster_rcnn_resnet152_v1_640x640_coco17',\n","        'pipeline_file': 'faster_rcnn_resnet152_v1_640x640_coco17_tpu-8.config',\n","        'batch_size': 4,\n","        'checkpoint_path' : '/content/drive/MyDrive/colabData/F-RCNN/checkpoint/ckpt-0'\n","    },\n","    'ssd_resnet152_v1_fpn': {\n","        'model_name': 'ssd_resnet152_v1_fpn_640x640_coco17',\n","        'pipeline_file': 'ssd_resnet152_v1_fpn_640x640_coco17_tpu-8.config',\n","        'batch_size': 16,\n","        'checkpoint_path' : '/content/drive/MyDrive/colabData/SSD_ResNet/checkpoint/ckpt-0'\n","    }\n","}\n","\n","# Pilih model yang ingin yang dipakai\n","# Pilih sebuah model dengan ambil dari > `MODELS_CONFIG`.\n","selected_model = 'ssd_resnet152_v1_fpn'\n","print(\"Selected Model: {}\".format(selected_model))\n","\n","# Nama model deteksi objek yang akan digunakan.\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","print(\"Model: {}\".format(MODEL))\n","\n","# Nama file pipeline di API deteksi objek tensorflow.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","print(\"Pipeline Config File: {}\".format(pipeline_file))\n","\n","# Ukuran Training Batch yang cocok dengan memori GPU Tesla K80 milik Colab untuk model yang dipilih.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']\n","print(\"Batch Size: {}\".format(batch_size))\n","\n","# Checkpoint pre-trained model\n","fine_tune_checkpoint = MODELS_CONFIG[selected_model]['checkpoint_path']\n","print(\"Pretrained Model Path: {}\".format(fine_tune_checkpoint))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Selected Model: ssd_resnet152_v1_fpn\n","Model: ssd_resnet152_v1_fpn_640x640_coco17\n","Pipeline Config File: ssd_resnet152_v1_fpn_640x640_coco17_tpu-8.config\n","Batch Size: 16\n","Pretrained Model Path: /content/drive/MyDrive/colabData/SSD_ResNet/checkpoint/ckpt-0\n"]}]},{"cell_type":"code","metadata":{"id":"jLqdPXCrcbti","executionInfo":{"status":"ok","timestamp":1632031612893,"user_tz":-420,"elapsed":305,"user":{"displayName":"Afkaar Arrachmandhika Muhammad Lanang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11774006176532521439"}}},"source":["# PENTING!: Connect ke drive dahulu sebelum mulai cell ini\n","# PENTING!: Update nama-nama TFRecord berikut dari \"cells\" and \"cells_label_map\" ke file yang dipunya!\n","\n","train_record_fname = '/content/drive/MyDrive/colabData/train.record'\n","test_record_fname = '/content/drive/MyDrive/colabData/test.record'\n","label_map_pbtxt_fname = '/content/drive/MyDrive/colabData/label_map.pbtxt'"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GEjas-_fFj5","executionInfo":{"status":"ok","timestamp":1632031614129,"user_tz":-420,"elapsed":4,"user":{"displayName":"Afkaar Arrachmandhika Muhammad Lanang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11774006176532521439"}}},"source":["import os\n","pipeline_fname = os.path.join('/content/models/research/object_detection/configs/tf2', pipeline_file)\n"," \n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"UaKH3HBffKbv","executionInfo":{"status":"ok","timestamp":1632031616976,"user_tz":-420,"elapsed":314,"user":{"displayName":"Afkaar Arrachmandhika Muhammad Lanang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11774006176532521439"}}},"source":["def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"O4zb5s1pfMZv","executionInfo":{"status":"ok","timestamp":1632031620032,"user_tz":-420,"elapsed":1789,"user":{"displayName":"Afkaar Arrachmandhika Muhammad Lanang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11774006176532521439"}}},"source":["import re\n"," \n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","\n","if num_classes > 1:\n","  learning_type = \"classification\"\n","else:\n","  learning_type = \"detection\"\n","\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('fine_tune_checkpoint: \".*?\"',\n","               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # file tfrecord train dan test.\n","    s = re.sub(\n","        '(input_path: \".*?)(train2017)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub(\n","        '(input_path: \".*?)(val2017)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n"," \n","    # label_map_path\n","    s = re.sub(\n","        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n"," \n","    # Atur training batch_size.\n","    s = re.sub('batch_size: [0-9]+',\n","               'batch_size: {}'.format(batch_size), s)\n"," \n","    # Atur training steps, num_steps\n","    s = re.sub('num_steps: [0-9]+',\n","               'num_steps: {}'.format(num_steps), s)\n","    \n","    # Atur Jumlah classes num_classes.\n","    s = re.sub('num_classes: [0-9]+',\n","               'num_classes: {}'.format(num_classes), s)\n","    \n","    # Atur Checkpoint Type\n","    s = re.sub('fine_tune_checkpoint_type: \".*?\"', 'fine_tune_checkpoint_type: \"{}\"'.format(learning_type), s)\n","    \n","    f.write(s)"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"skhRbrp89xrS","executionInfo":{"status":"ok","timestamp":1632031627846,"user_tz":-420,"elapsed":305,"user":{"displayName":"Afkaar Arrachmandhika Muhammad Lanang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11774006176532521439"}}},"source":["# Edit Main Model Eval Time\n","python_file = \"/content/models/research/object_detection/model_main_tf2.py\"\n","with open(python_file) as f:\n","    s = f.read()\n","with open(python_file, 'w') as f:\n","    \n","    # fine_tune_checkpoint\n","    s = re.sub('wait_interval=300',\n","               'wait_interval=600', s)\n","    \n","    f.write(s)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"unOEkmKh-ZAx","executionInfo":{"status":"ok","timestamp":1632031636214,"user_tz":-420,"elapsed":323,"user":{"displayName":"Afkaar Arrachmandhika Muhammad Lanang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11774006176532521439"}},"outputId":"c5b8330b-d2e4-40d5-8dd7-a3d78034a981"},"source":["!cat {python_file}"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["# Lint as: python3\n","# Copyright 2020 The TensorFlow Authors. All Rights Reserved.\n","#\n","# Licensed under the Apache License, Version 2.0 (the \"License\");\n","# you may not use this file except in compliance with the License.\n","# You may obtain a copy of the License at\n","#\n","#     http://www.apache.org/licenses/LICENSE-2.0\n","#\n","# Unless required by applicable law or agreed to in writing, software\n","# distributed under the License is distributed on an \"AS IS\" BASIS,\n","# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","# See the License for the specific language governing permissions and\n","# limitations under the License.\n","# ==============================================================================\n","\n","r\"\"\"Creates and runs TF2 object detection models.\n","\n","For local training/evaluation run:\n","PIPELINE_CONFIG_PATH=path/to/pipeline.config\n","MODEL_DIR=/tmp/model_outputs\n","NUM_TRAIN_STEPS=10000\n","SAMPLE_1_OF_N_EVAL_EXAMPLES=1\n","python model_main_tf2.py -- \\\n","  --model_dir=$MODEL_DIR --num_train_steps=$NUM_TRAIN_STEPS \\\n","  --sample_1_of_n_eval_examples=$SAMPLE_1_OF_N_EVAL_EXAMPLES \\\n","  --pipeline_config_path=$PIPELINE_CONFIG_PATH \\\n","  --alsologtostderr\n","\"\"\"\n","from absl import flags\n","import tensorflow.compat.v2 as tf\n","from object_detection import model_lib_v2\n","\n","flags.DEFINE_string('pipeline_config_path', None, 'Path to pipeline config '\n","                    'file.')\n","flags.DEFINE_integer('num_train_steps', None, 'Number of train steps.')\n","flags.DEFINE_bool('eval_on_train_data', False, 'Enable evaluating on train '\n","                  'data (only supported in distributed training).')\n","flags.DEFINE_integer('sample_1_of_n_eval_examples', None, 'Will sample one of '\n","                     'every n eval input examples, where n is provided.')\n","flags.DEFINE_integer('sample_1_of_n_eval_on_train_examples', 5, 'Will sample '\n","                     'one of every n train input examples for evaluation, '\n","                     'where n is provided. This is only used if '\n","                     '`eval_training_data` is True.')\n","flags.DEFINE_string(\n","    'model_dir', None, 'Path to output model directory '\n","                       'where event and checkpoint files will be written.')\n","flags.DEFINE_string(\n","    'checkpoint_dir', None, 'Path to directory holding a checkpoint.  If '\n","    '`checkpoint_dir` is provided, this binary operates in eval-only mode, '\n","    'writing resulting metrics to `model_dir`.')\n","\n","flags.DEFINE_integer('eval_timeout', 3600, 'Number of seconds to wait for an'\n","                     'evaluation checkpoint before exiting.')\n","\n","flags.DEFINE_bool('use_tpu', False, 'Whether the job is executing on a TPU.')\n","flags.DEFINE_string(\n","    'tpu_name',\n","    default=None,\n","    help='Name of the Cloud TPU for Cluster Resolvers.')\n","flags.DEFINE_integer(\n","    'num_workers', 1, 'When num_workers > 1, training uses '\n","    'MultiWorkerMirroredStrategy. When num_workers = 1 it uses '\n","    'MirroredStrategy.')\n","flags.DEFINE_integer(\n","    'checkpoint_every_n', 1000, 'Integer defining how often we checkpoint.')\n","flags.DEFINE_boolean('record_summaries', True,\n","                     ('Whether or not to record summaries defined by the model'\n","                      ' or the training pipeline. This does not impact the'\n","                      ' summaries of the loss values which are always'\n","                      ' recorded.'))\n","\n","FLAGS = flags.FLAGS\n","\n","\n","def main(unused_argv):\n","  flags.mark_flag_as_required('model_dir')\n","  flags.mark_flag_as_required('pipeline_config_path')\n","  tf.config.set_soft_device_placement(True)\n","\n","  if FLAGS.checkpoint_dir:\n","    model_lib_v2.eval_continuously(\n","        pipeline_config_path=FLAGS.pipeline_config_path,\n","        model_dir=FLAGS.model_dir,\n","        train_steps=FLAGS.num_train_steps,\n","        sample_1_of_n_eval_examples=FLAGS.sample_1_of_n_eval_examples,\n","        sample_1_of_n_eval_on_train_examples=(\n","            FLAGS.sample_1_of_n_eval_on_train_examples),\n","        checkpoint_dir=FLAGS.checkpoint_dir,\n","        wait_interval=600, timeout=FLAGS.eval_timeout)\n","  else:\n","    if FLAGS.use_tpu:\n","      # TPU is automatically inferred if tpu_name is None and\n","      # we are running under cloud ai-platform.\n","      resolver = tf.distribute.cluster_resolver.TPUClusterResolver(\n","          FLAGS.tpu_name)\n","      tf.config.experimental_connect_to_cluster(resolver)\n","      tf.tpu.experimental.initialize_tpu_system(resolver)\n","      strategy = tf.distribute.experimental.TPUStrategy(resolver)\n","    elif FLAGS.num_workers > 1:\n","      strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy()\n","    else:\n","      strategy = tf.compat.v2.distribute.MirroredStrategy()\n","\n","    with strategy.scope():\n","      model_lib_v2.train_loop(\n","          pipeline_config_path=FLAGS.pipeline_config_path,\n","          model_dir=FLAGS.model_dir,\n","          train_steps=FLAGS.num_train_steps,\n","          use_tpu=FLAGS.use_tpu,\n","          checkpoint_every_n=FLAGS.checkpoint_every_n,\n","          record_summaries=FLAGS.record_summaries)\n","\n","if __name__ == '__main__':\n","  tf.compat.v1.app.run()\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6NG_fSsefOMG","executionInfo":{"status":"ok","timestamp":1632031637684,"user_tz":-420,"elapsed":11,"user":{"displayName":"Afkaar Arrachmandhika Muhammad Lanang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11774006176532521439"}},"outputId":"93d061cf-75cb-47f2-a85f-eabb2bd5b492"},"source":["!cat {pipeline_fname}"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["# SSD with Resnet 152 v1 FPN feature extractor, shared box predictor and focal\n","# loss (a.k.a Retinanet).\n","# See Lin et al, https://arxiv.org/abs/1708.02002\n","# Trained on COCO, initialized from Imagenet classification checkpoint\n","# Train on TPU-8\n","#\n","# Achieves 35.6 mAP on COCO17 Val\n","\n","model {\n","  ssd {\n","    inplace_batchnorm_update: true\n","    freeze_batchnorm: false\n","    num_classes: 1\n","    box_coder {\n","      faster_rcnn_box_coder {\n","        y_scale: 10.0\n","        x_scale: 10.0\n","        height_scale: 5.0\n","        width_scale: 5.0\n","      }\n","    }\n","    matcher {\n","      argmax_matcher {\n","        matched_threshold: 0.5\n","        unmatched_threshold: 0.5\n","        ignore_thresholds: false\n","        negatives_lower_than_unmatched: true\n","        force_match_for_each_row: true\n","        use_matmul_gather: true\n","      }\n","    }\n","    similarity_calculator {\n","      iou_similarity {\n","      }\n","    }\n","    encode_background_as_zeros: true\n","    anchor_generator {\n","      multiscale_anchor_generator {\n","        min_level: 3\n","        max_level: 7\n","        anchor_scale: 4.0\n","        aspect_ratios: [1.0, 2.0, 0.5]\n","        scales_per_octave: 2\n","      }\n","    }\n","    image_resizer {\n","      fixed_shape_resizer {\n","        height: 640\n","        width: 640\n","      }\n","    }\n","    box_predictor {\n","      weight_shared_convolutional_box_predictor {\n","        depth: 256\n","        class_prediction_bias_init: -4.6\n","        conv_hyperparams {\n","          activation: RELU_6,\n","          regularizer {\n","            l2_regularizer {\n","              weight: 0.0004\n","            }\n","          }\n","          initializer {\n","            random_normal_initializer {\n","              stddev: 0.01\n","              mean: 0.0\n","            }\n","          }\n","          batch_norm {\n","            scale: true,\n","            decay: 0.997,\n","            epsilon: 0.001,\n","          }\n","        }\n","        num_layers_before_predictor: 4\n","        kernel_size: 3\n","      }\n","    }\n","    feature_extractor {\n","      type: 'ssd_resnet152_v1_fpn_keras'\n","      fpn {\n","        min_level: 3\n","        max_level: 7\n","      }\n","      min_depth: 16\n","      depth_multiplier: 1.0\n","      conv_hyperparams {\n","        activation: RELU_6,\n","        regularizer {\n","          l2_regularizer {\n","            weight: 0.0004\n","          }\n","        }\n","        initializer {\n","          truncated_normal_initializer {\n","            stddev: 0.03\n","            mean: 0.0\n","          }\n","        }\n","        batch_norm {\n","          scale: true,\n","          decay: 0.997,\n","          epsilon: 0.001,\n","        }\n","      }\n","      override_base_feature_extractor_hyperparams: true\n","    }\n","    loss {\n","      classification_loss {\n","        weighted_sigmoid_focal {\n","          alpha: 0.25\n","          gamma: 2.0\n","        }\n","      }\n","      localization_loss {\n","        weighted_smooth_l1 {\n","        }\n","      }\n","      classification_weight: 1.0\n","      localization_weight: 1.0\n","    }\n","    normalize_loss_by_num_matches: true\n","    normalize_loc_loss_by_codesize: true\n","    post_processing {\n","      batch_non_max_suppression {\n","        score_threshold: 1e-8\n","        iou_threshold: 0.6\n","        max_detections_per_class: 100\n","        max_total_detections: 100\n","      }\n","      score_converter: SIGMOID\n","    }\n","  }\n","}\n","\n","train_config: {\n","  fine_tune_checkpoint_version: V2\n","  fine_tune_checkpoint: \"/content/drive/MyDrive/colabData/SSD_ResNet/checkpoint/ckpt-0\"\n","  fine_tune_checkpoint_type: \"detection\"\n","  batch_size: 16\n","  sync_replicas: true\n","  startup_delay_steps: 0\n","  replicas_to_aggregate: 8\n","  use_bfloat16: true\n","  num_steps: 10000\n","  data_augmentation_options {\n","    random_horizontal_flip {\n","    }\n","  }\n","  data_augmentation_options {\n","    random_crop_image {\n","      min_object_covered: 0.0\n","      min_aspect_ratio: 0.75\n","      max_aspect_ratio: 3.0\n","      min_area: 0.75\n","      max_area: 1.0\n","      overlap_thresh: 0.0\n","    }\n","  }\n","  optimizer {\n","    momentum_optimizer: {\n","      learning_rate: {\n","        cosine_decay_learning_rate {\n","          learning_rate_base: .04\n","          total_steps: 25000\n","          warmup_learning_rate: .013333\n","          warmup_steps: 2000\n","        }\n","      }\n","      momentum_optimizer_value: 0.9\n","    }\n","    use_moving_average: false\n","  }\n","  max_number_of_boxes: 100\n","  unpad_groundtruth_tensors: false\n","}\n","\n","train_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/colabData/label_map.pbtxt\"\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/colabData/train.record\"\n","  }\n","}\n","\n","eval_config: {\n","  metrics_set: \"coco_detection_metrics\"\n","  use_moving_averages: false\n","}\n","\n","eval_input_reader: {\n","  label_map_path: \"/content/drive/MyDrive/colabData/label_map.pbtxt\"\n","  shuffle: false\n","  num_epochs: 1\n","  tf_record_input_reader {\n","    input_path: \"/content/drive/MyDrive/colabData/test.record\"\n","  }\n","}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kgRHLKTLfRDw","executionInfo":{"status":"ok","timestamp":1632031641592,"user_tz":-420,"elapsed":321,"user":{"displayName":"Afkaar Arrachmandhika Muhammad Lanang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11774006176532521439"}},"outputId":"85ce2d84-b62a-4e3e-bebf-cb62bec77355"},"source":["%cd /content/drive/MyDrive/colabData/"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/colabData\n"]}]},{"cell_type":"code","metadata":{"id":"sfBY8BzmfVMO","executionInfo":{"status":"ok","timestamp":1632031644315,"user_tz":-420,"elapsed":1208,"user":{"displayName":"Afkaar Arrachmandhika Muhammad Lanang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11774006176532521439"}}},"source":["model_dir = 'trained_model/{}/'.format(selected_model)\n","!rm -r /content/drive/MyDrive/colabData/trained_model/{selected_model}/eval"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YJ5a3gYifX-9","executionInfo":{"status":"ok","timestamp":1632038526250,"user_tz":-420,"elapsed":6348910,"user":{"displayName":"Afkaar Arrachmandhika Muhammad Lanang","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"11774006176532521439"}},"outputId":"f77d9171-b6e0-4647-ca19-864889609f59"},"source":["!python /content/models/research/object_detection/model_main_tf2.py \\\n","    --pipeline_config_path={pipeline_fname} \\\n","    --model_dir={model_dir} \\\n","    --checkpoint_dir={model_dir} \\\n","    --alsologtostderr"],"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["2021-09-19 06:16:19.878140: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:16:19.887057: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:16:19.887718: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n","W0919 06:16:19.891664 139976889247616 model_lib_v2.py:1082] Forced number of epochs for all eval validations to be 1.\n","INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n","I0919 06:16:19.891886 139976889247616 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n","INFO:tensorflow:Maybe overwriting use_bfloat16: False\n","I0919 06:16:19.891979 139976889247616 config_util.py:552] Maybe overwriting use_bfloat16: False\n","INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n","I0919 06:16:19.892068 139976889247616 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n","WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","W0919 06:16:19.892192 139976889247616 model_lib_v2.py:1103] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n","2021-09-19 06:16:19.895342: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX512F\n","To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2021-09-19 06:16:19.895574: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:16:19.896165: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:16:19.896736: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:16:20.401649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:16:20.402321: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:16:20.402927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2021-09-19 06:16:20.403457: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2021-09-19 06:16:20.403511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13839 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n","INFO:tensorflow:Reading unweighted datasets: ['/content/drive/MyDrive/colabData/test.record']\n","I0919 06:16:20.528903 139976889247616 dataset_builder.py:163] Reading unweighted datasets: ['/content/drive/MyDrive/colabData/test.record']\n","INFO:tensorflow:Reading record datasets for input file: ['/content/drive/MyDrive/colabData/test.record']\n","I0919 06:16:20.529308 139976889247616 dataset_builder.py:80] Reading record datasets for input file: ['/content/drive/MyDrive/colabData/test.record']\n","INFO:tensorflow:Number of filenames to read: 1\n","I0919 06:16:20.529464 139976889247616 dataset_builder.py:81] Number of filenames to read: 1\n","WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n","W0919 06:16:20.529540 139976889247616 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","W0919 06:16:20.531088 139976889247616 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","W0919 06:16:20.549465 139976889247616 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.data.Dataset.map()\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","W0919 06:16:24.096663 139976889247616 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:206: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0919 06:16:25.205906 139976889247616 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","I0919 06:16:27.739631 139976889247616 checkpoint_utils.py:140] Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","INFO:tensorflow:Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-1\n","I0919 06:16:27.953498 139976889247616 checkpoint_utils.py:149] Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-1\n","/usr/local/lib/python3.7/dist-packages/keras/backend.py:401: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n","  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '\n","2021-09-19 06:16:29.602298: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n","2021-09-19 06:17:04.126311: I tensorflow/stream_executor/cuda/cuda_dnn.cc:369] Loaded cuDNN version 8005\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","W0919 06:17:06.679087 139976889247616 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/object_detection/eval_util.py:929: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.cast` instead.\n","INFO:tensorflow:Finished eval step 0\n","I0919 06:17:06.687535 139976889247616 model_lib_v2.py:958] Finished eval step 0\n","WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","W0919 06:17:06.811911 139976889247616 deprecation.py:345] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:464: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","tf.py_func is deprecated in TF V2. Instead, there are two\n","    options available in V2.\n","    - tf.py_function takes a python function which manipulates tf eager\n","    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n","    an ndarray (just call tensor.numpy()) but having access to eager tensors\n","    means `tf.py_function`s can use accelerators such as GPUs as well as\n","    being differentiable using a gradient tape.\n","    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n","    (it is not differentiable, and manipulates numpy arrays). It drops the\n","    stateful argument making all functions stateful.\n","    \n","INFO:tensorflow:Performing evaluation on 65 images.\n","I0919 06:17:51.653648 139976889247616 coco_evaluation.py:293] Performing evaluation on 65 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0919 06:17:51.654067 139976889247616 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0919 06:17:51.657582 139976889247616 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.34s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000\n","INFO:tensorflow:Eval metrics at step 0\n","I0919 06:17:52.054981 139976889247616 model_lib_v2.py:1007] Eval metrics at step 0\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.000000\n","I0919 06:17:52.063631 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP: 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.000000\n","I0919 06:17:52.064825 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000000\n","I0919 06:17:52.065917 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.000000\n","I0919 06:17:52.066891 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (small): 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.000000\n","I0919 06:17:52.067881 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (medium): 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.000000\n","I0919 06:17:52.068863 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (large): 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.000000\n","I0919 06:17:52.069864 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@1: 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.000000\n","I0919 06:17:52.070825 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@10: 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.000000\n","I0919 06:17:52.071808 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100: 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n","I0919 06:17:52.072844 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.000000\n","I0919 06:17:52.073850 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.000000\n","I0919 06:17:52.075008 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (large): 0.000000\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.720800\n","I0919 06:17:52.075947 139976889247616 model_lib_v2.py:1010] \t+ Loss/localization_loss: 0.720800\n","INFO:tensorflow:\t+ Loss/classification_loss: 1.139088\n","I0919 06:17:52.076924 139976889247616 model_lib_v2.py:1010] \t+ Loss/classification_loss: 1.139088\n","INFO:tensorflow:\t+ Loss/regularization_loss: 0.284941\n","I0919 06:17:52.077828 139976889247616 model_lib_v2.py:1010] \t+ Loss/regularization_loss: 0.284941\n","INFO:tensorflow:\t+ Loss/total_loss: 2.144829\n","I0919 06:17:52.078738 139976889247616 model_lib_v2.py:1010] \t+ Loss/total_loss: 2.144829\n","INFO:tensorflow:Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","I0919 06:26:28.044605 139976889247616 checkpoint_utils.py:140] Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","INFO:tensorflow:Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-2\n","I0919 06:26:28.269443 139976889247616 checkpoint_utils.py:149] Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-2\n","INFO:tensorflow:Finished eval step 0\n","I0919 06:26:48.346238 139976889247616 model_lib_v2.py:958] Finished eval step 0\n","INFO:tensorflow:Performing evaluation on 65 images.\n","I0919 06:26:57.358407 139976889247616 coco_evaluation.py:293] Performing evaluation on 65 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0919 06:26:57.358793 139976889247616 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0919 06:26:57.361882 139976889247616 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.35s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.001\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.003\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.010\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.106\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.014\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.111\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.222\n","INFO:tensorflow:Eval metrics at step 1000\n","I0919 06:26:57.773492 139976889247616 model_lib_v2.py:1007] Eval metrics at step 1000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.000394\n","I0919 06:26:57.781217 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP: 0.000394\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.001702\n","I0919 06:26:57.782542 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.001702\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000026\n","I0919 06:26:57.783658 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000026\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.001320\n","I0919 06:26:57.784722 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (small): 0.001320\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.000326\n","I0919 06:26:57.785785 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (medium): 0.000326\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.003685\n","I0919 06:26:57.786857 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (large): 0.003685\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.002941\n","I0919 06:26:57.787914 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@1: 0.002941\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.010294\n","I0919 06:26:57.788962 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@10: 0.010294\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.105882\n","I0919 06:26:57.790015 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100: 0.105882\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.014286\n","I0919 06:26:57.791076 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (small): 0.014286\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.111111\n","I0919 06:26:57.792137 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.111111\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.222222\n","I0919 06:26:57.793308 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (large): 0.222222\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.705764\n","I0919 06:26:57.794168 139976889247616 model_lib_v2.py:1010] \t+ Loss/localization_loss: 0.705764\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.774756\n","I0919 06:26:57.795163 139976889247616 model_lib_v2.py:1010] \t+ Loss/classification_loss: 0.774756\n","INFO:tensorflow:\t+ Loss/regularization_loss: 273.498596\n","I0919 06:26:57.796086 139976889247616 model_lib_v2.py:1010] \t+ Loss/regularization_loss: 273.498596\n","INFO:tensorflow:\t+ Loss/total_loss: 274.979126\n","I0919 06:26:57.797084 139976889247616 model_lib_v2.py:1010] \t+ Loss/total_loss: 274.979126\n","INFO:tensorflow:Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","I0919 06:36:28.356118 139976889247616 checkpoint_utils.py:140] Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","INFO:tensorflow:Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-3\n","I0919 06:36:28.573983 139976889247616 checkpoint_utils.py:149] Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-3\n","INFO:tensorflow:Finished eval step 0\n","I0919 06:36:48.787545 139976889247616 model_lib_v2.py:958] Finished eval step 0\n","INFO:tensorflow:Performing evaluation on 65 images.\n","I0919 06:37:03.145147 139976889247616 coco_evaluation.py:293] Performing evaluation on 65 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0919 06:37:03.145539 139976889247616 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0919 06:37:03.148362 139976889247616 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.36s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.001\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.003\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.002\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.004\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.028\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.071\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.040\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.333\n","INFO:tensorflow:Eval metrics at step 2000\n","I0919 06:37:03.563225 139976889247616 model_lib_v2.py:1007] Eval metrics at step 2000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.000575\n","I0919 06:37:03.571065 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP: 0.000575\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.003030\n","I0919 06:37:03.572367 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.003030\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000089\n","I0919 06:37:03.573527 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.000089\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.000000\n","I0919 06:37:03.574489 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (small): 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.000652\n","I0919 06:37:03.575620 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (medium): 0.000652\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.002269\n","I0919 06:37:03.576823 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (large): 0.002269\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.004412\n","I0919 06:37:03.577979 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@1: 0.004412\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.027941\n","I0919 06:37:03.579104 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@10: 0.027941\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.070588\n","I0919 06:37:03.580234 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100: 0.070588\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n","I0919 06:37:03.581189 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.040000\n","I0919 06:37:03.582267 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.040000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.333333\n","I0919 06:37:03.583494 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (large): 0.333333\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.678899\n","I0919 06:37:03.584399 139976889247616 model_lib_v2.py:1010] \t+ Loss/localization_loss: 0.678899\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.837918\n","I0919 06:37:03.585311 139976889247616 model_lib_v2.py:1010] \t+ Loss/classification_loss: 0.837918\n","INFO:tensorflow:\t+ Loss/regularization_loss: 210.165207\n","I0919 06:37:03.586206 139976889247616 model_lib_v2.py:1010] \t+ Loss/regularization_loss: 210.165207\n","INFO:tensorflow:\t+ Loss/total_loss: 211.682022\n","I0919 06:37:03.587095 139976889247616 model_lib_v2.py:1010] \t+ Loss/total_loss: 211.682022\n","INFO:tensorflow:Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","I0919 06:46:28.671439 139976889247616 checkpoint_utils.py:140] Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","INFO:tensorflow:Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-4\n","I0919 06:46:28.897150 139976889247616 checkpoint_utils.py:149] Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-4\n","INFO:tensorflow:Finished eval step 0\n","I0919 06:46:50.190296 139976889247616 model_lib_v2.py:958] Finished eval step 0\n","INFO:tensorflow:Performing evaluation on 65 images.\n","I0919 06:47:04.449061 139976889247616 coco_evaluation.py:293] Performing evaluation on 65 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0919 06:47:04.449463 139976889247616 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0919 06:47:04.452405 139976889247616 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.34s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.007\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.029\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.002\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.052\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.005\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.001\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.113\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.007\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.244\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.311\n","INFO:tensorflow:Eval metrics at step 3000\n","I0919 06:47:04.852126 139976889247616 model_lib_v2.py:1007] Eval metrics at step 3000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.007291\n","I0919 06:47:04.860638 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP: 0.007291\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.029116\n","I0919 06:47:04.861974 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.029116\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.001974\n","I0919 06:47:04.863212 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.001974\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.007921\n","I0919 06:47:04.864333 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (small): 0.007921\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.052375\n","I0919 06:47:04.865460 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (medium): 0.052375\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.005383\n","I0919 06:47:04.866588 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (large): 0.005383\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.001471\n","I0919 06:47:04.867688 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@1: 0.001471\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.113235\n","I0919 06:47:04.868810 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@10: 0.113235\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.204412\n","I0919 06:47:04.869963 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100: 0.204412\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.007143\n","I0919 06:47:04.871138 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (small): 0.007143\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.244444\n","I0919 06:47:04.872282 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.244444\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.311111\n","I0919 06:47:04.873544 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (large): 0.311111\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.556083\n","I0919 06:47:04.874438 139976889247616 model_lib_v2.py:1010] \t+ Loss/localization_loss: 0.556083\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.774169\n","I0919 06:47:04.875414 139976889247616 model_lib_v2.py:1010] \t+ Loss/classification_loss: 0.774169\n","INFO:tensorflow:\t+ Loss/regularization_loss: 152.632996\n","I0919 06:47:04.876402 139976889247616 model_lib_v2.py:1010] \t+ Loss/regularization_loss: 152.632996\n","INFO:tensorflow:\t+ Loss/total_loss: 153.963257\n","I0919 06:47:04.877396 139976889247616 model_lib_v2.py:1010] \t+ Loss/total_loss: 153.963257\n","INFO:tensorflow:Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","I0919 06:56:28.956200 139976889247616 checkpoint_utils.py:140] Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","INFO:tensorflow:Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-5\n","I0919 06:56:29.165491 139976889247616 checkpoint_utils.py:149] Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-5\n","INFO:tensorflow:Finished eval step 0\n","I0919 06:56:51.884511 139976889247616 model_lib_v2.py:958] Finished eval step 0\n","INFO:tensorflow:Performing evaluation on 65 images.\n","I0919 06:57:06.298456 139976889247616 coco_evaluation.py:293] Performing evaluation on 65 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0919 06:57:06.298962 139976889247616 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0919 06:57:06.302002 139976889247616 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.33s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.028\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.085\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.012\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.083\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.032\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.071\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.147\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.240\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.171\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.227\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.411\n","INFO:tensorflow:Eval metrics at step 4000\n","I0919 06:57:06.700927 139976889247616 model_lib_v2.py:1007] Eval metrics at step 4000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.028397\n","I0919 06:57:06.709200 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP: 0.028397\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.084777\n","I0919 06:57:06.710458 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.084777\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.011550\n","I0919 06:57:06.711617 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.011550\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.009852\n","I0919 06:57:06.712778 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (small): 0.009852\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.083125\n","I0919 06:57:06.713917 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (medium): 0.083125\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.031780\n","I0919 06:57:06.715033 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (large): 0.031780\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.070588\n","I0919 06:57:06.716024 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@1: 0.070588\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.147059\n","I0919 06:57:06.717181 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@10: 0.147059\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.239706\n","I0919 06:57:06.718334 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100: 0.239706\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.171429\n","I0919 06:57:06.719532 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (small): 0.171429\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.226667\n","I0919 06:57:06.720652 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.226667\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.411111\n","I0919 06:57:06.721945 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (large): 0.411111\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.509730\n","I0919 06:57:06.722890 139976889247616 model_lib_v2.py:1010] \t+ Loss/localization_loss: 0.509730\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.788725\n","I0919 06:57:06.723789 139976889247616 model_lib_v2.py:1010] \t+ Loss/classification_loss: 0.788725\n","INFO:tensorflow:\t+ Loss/regularization_loss: 111.184090\n","I0919 06:57:06.724687 139976889247616 model_lib_v2.py:1010] \t+ Loss/regularization_loss: 111.184090\n","INFO:tensorflow:\t+ Loss/total_loss: 112.482552\n","I0919 06:57:06.725574 139976889247616 model_lib_v2.py:1010] \t+ Loss/total_loss: 112.482552\n","INFO:tensorflow:Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","I0919 07:06:29.250459 139976889247616 checkpoint_utils.py:140] Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","INFO:tensorflow:Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-6\n","I0919 07:06:29.469828 139976889247616 checkpoint_utils.py:149] Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-6\n","INFO:tensorflow:Finished eval step 0\n","I0919 07:06:50.642363 139976889247616 model_lib_v2.py:958] Finished eval step 0\n","INFO:tensorflow:Performing evaluation on 65 images.\n","I0919 07:06:59.768106 139976889247616 coco_evaluation.py:293] Performing evaluation on 65 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0919 07:06:59.768535 139976889247616 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0919 07:06:59.771492 139976889247616 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.34s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.098\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.001\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.030\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.102\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.104\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.026\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.221\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.464\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.276\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.367\n","INFO:tensorflow:Eval metrics at step 5000\n","I0919 07:07:00.172453 139976889247616 model_lib_v2.py:1007] Eval metrics at step 5000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.028568\n","I0919 07:07:00.180100 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP: 0.028568\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.098489\n","I0919 07:07:00.181356 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.098489\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.001200\n","I0919 07:07:00.182504 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.001200\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.030304\n","I0919 07:07:00.183608 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (small): 0.030304\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.101944\n","I0919 07:07:00.184700 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (medium): 0.101944\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.103774\n","I0919 07:07:00.185791 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (large): 0.103774\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.026471\n","I0919 07:07:00.186892 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@1: 0.026471\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.220588\n","I0919 07:07:00.187970 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@10: 0.220588\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.326471\n","I0919 07:07:00.189059 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100: 0.326471\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.464286\n","I0919 07:07:00.190153 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (small): 0.464286\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.275556\n","I0919 07:07:00.191280 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.275556\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.366667\n","I0919 07:07:00.192540 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (large): 0.366667\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.559567\n","I0919 07:07:00.193427 139976889247616 model_lib_v2.py:1010] \t+ Loss/localization_loss: 0.559567\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.789758\n","I0919 07:07:00.194324 139976889247616 model_lib_v2.py:1010] \t+ Loss/classification_loss: 0.789758\n","INFO:tensorflow:\t+ Loss/regularization_loss: 81.490929\n","I0919 07:07:00.195233 139976889247616 model_lib_v2.py:1010] \t+ Loss/regularization_loss: 81.490929\n","INFO:tensorflow:\t+ Loss/total_loss: 82.840256\n","I0919 07:07:00.196323 139976889247616 model_lib_v2.py:1010] \t+ Loss/total_loss: 82.840256\n","INFO:tensorflow:Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","I0919 07:16:29.523051 139976889247616 checkpoint_utils.py:140] Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","INFO:tensorflow:Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-7\n","I0919 07:16:29.764149 139976889247616 checkpoint_utils.py:149] Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-7\n","INFO:tensorflow:Finished eval step 0\n","I0919 07:16:51.206988 139976889247616 model_lib_v2.py:958] Finished eval step 0\n","INFO:tensorflow:Performing evaluation on 65 images.\n","I0919 07:17:05.447775 139976889247616 coco_evaluation.py:293] Performing evaluation on 65 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0919 07:17:05.448151 139976889247616 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0919 07:17:05.451000 139976889247616 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.33s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.108\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.309\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.029\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.159\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.157\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.154\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.178\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.316\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.394\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.471\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.364\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.422\n","INFO:tensorflow:Eval metrics at step 6000\n","I0919 07:17:05.844685 139976889247616 model_lib_v2.py:1007] Eval metrics at step 6000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.107951\n","I0919 07:17:05.852189 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP: 0.107951\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.309168\n","I0919 07:17:05.853551 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.309168\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.029291\n","I0919 07:17:05.854918 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.029291\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.158835\n","I0919 07:17:05.856104 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (small): 0.158835\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.156606\n","I0919 07:17:05.857253 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (medium): 0.156606\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.154470\n","I0919 07:17:05.858384 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (large): 0.154470\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.177941\n","I0919 07:17:05.859533 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@1: 0.177941\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.316176\n","I0919 07:17:05.860648 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@10: 0.316176\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.394118\n","I0919 07:17:05.861928 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100: 0.394118\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.471429\n","I0919 07:17:05.863056 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (small): 0.471429\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.364444\n","I0919 07:17:05.864165 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.364444\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.422222\n","I0919 07:17:05.865362 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (large): 0.422222\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.449598\n","I0919 07:17:05.866239 139976889247616 model_lib_v2.py:1010] \t+ Loss/localization_loss: 0.449598\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.653648\n","I0919 07:17:05.867177 139976889247616 model_lib_v2.py:1010] \t+ Loss/classification_loss: 0.653648\n","INFO:tensorflow:\t+ Loss/regularization_loss: 60.247463\n","I0919 07:17:05.868128 139976889247616 model_lib_v2.py:1010] \t+ Loss/regularization_loss: 60.247463\n","INFO:tensorflow:\t+ Loss/total_loss: 61.350708\n","I0919 07:17:05.869011 139976889247616 model_lib_v2.py:1010] \t+ Loss/total_loss: 61.350708\n","INFO:tensorflow:Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","I0919 07:26:29.851544 139976889247616 checkpoint_utils.py:140] Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","INFO:tensorflow:Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-9\n","I0919 07:26:30.098038 139976889247616 checkpoint_utils.py:149] Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-9\n","INFO:tensorflow:Finished eval step 0\n","I0919 07:26:51.284478 139976889247616 model_lib_v2.py:958] Finished eval step 0\n","INFO:tensorflow:Performing evaluation on 65 images.\n","I0919 07:27:05.400012 139976889247616 coco_evaluation.py:293] Performing evaluation on 65 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0919 07:27:05.400480 139976889247616 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0919 07:27:05.403330 139976889247616 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.33s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.100\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.259\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.055\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.152\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.203\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.219\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.097\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.399\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.468\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.486\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.458\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.489\n","INFO:tensorflow:Eval metrics at step 8000\n","I0919 07:27:05.795368 139976889247616 model_lib_v2.py:1007] Eval metrics at step 8000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.100172\n","I0919 07:27:05.803072 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP: 0.100172\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.258744\n","I0919 07:27:05.804367 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.258744\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.055248\n","I0919 07:27:05.805583 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.055248\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.152363\n","I0919 07:27:05.806738 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (small): 0.152363\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.202614\n","I0919 07:27:05.807868 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (medium): 0.202614\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.219184\n","I0919 07:27:05.809017 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (large): 0.219184\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.097059\n","I0919 07:27:05.810213 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@1: 0.097059\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.398529\n","I0919 07:27:05.811428 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@10: 0.398529\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.467647\n","I0919 07:27:05.812534 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100: 0.467647\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.485714\n","I0919 07:27:05.813780 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (small): 0.485714\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.457778\n","I0919 07:27:05.814969 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.457778\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.488889\n","I0919 07:27:05.816192 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (large): 0.488889\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.321587\n","I0919 07:27:05.817116 139976889247616 model_lib_v2.py:1010] \t+ Loss/localization_loss: 0.321587\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.597343\n","I0919 07:27:05.818037 139976889247616 model_lib_v2.py:1010] \t+ Loss/classification_loss: 0.597343\n","INFO:tensorflow:\t+ Loss/regularization_loss: 34.167465\n","I0919 07:27:05.819001 139976889247616 model_lib_v2.py:1010] \t+ Loss/regularization_loss: 34.167465\n","INFO:tensorflow:\t+ Loss/total_loss: 35.086395\n","I0919 07:27:05.819927 139976889247616 model_lib_v2.py:1010] \t+ Loss/total_loss: 35.086395\n","INFO:tensorflow:Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","I0919 07:36:30.171564 139976889247616 checkpoint_utils.py:140] Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","INFO:tensorflow:Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-10\n","I0919 07:36:30.404950 139976889247616 checkpoint_utils.py:149] Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-10\n","INFO:tensorflow:Finished eval step 0\n","I0919 07:36:50.850883 139976889247616 model_lib_v2.py:958] Finished eval step 0\n","INFO:tensorflow:Performing evaluation on 65 images.\n","I0919 07:37:05.307193 139976889247616 coco_evaluation.py:293] Performing evaluation on 65 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0919 07:37:05.307704 139976889247616 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0919 07:37:05.311104 139976889247616 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.32s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.067\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.170\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.010\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.126\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.153\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.237\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.106\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.287\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.460\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.521\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.420\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.567\n","INFO:tensorflow:Eval metrics at step 9000\n","I0919 07:37:05.698944 139976889247616 model_lib_v2.py:1007] Eval metrics at step 9000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.067097\n","I0919 07:37:05.710401 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP: 0.067097\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.170176\n","I0919 07:37:05.711756 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.170176\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.009913\n","I0919 07:37:05.712915 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.009913\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.125814\n","I0919 07:37:05.714066 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (small): 0.125814\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.152712\n","I0919 07:37:05.715219 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (medium): 0.152712\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.237079\n","I0919 07:37:05.716375 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (large): 0.237079\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.105882\n","I0919 07:37:05.717334 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@1: 0.105882\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.286765\n","I0919 07:37:05.718415 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@10: 0.286765\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.460294\n","I0919 07:37:05.719511 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100: 0.460294\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.521429\n","I0919 07:37:05.720616 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (small): 0.521429\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.420000\n","I0919 07:37:05.721744 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.420000\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.566667\n","I0919 07:37:05.723019 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (large): 0.566667\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.368460\n","I0919 07:37:05.723903 139976889247616 model_lib_v2.py:1010] \t+ Loss/localization_loss: 0.368460\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.719683\n","I0919 07:37:05.724853 139976889247616 model_lib_v2.py:1010] \t+ Loss/classification_loss: 0.719683\n","INFO:tensorflow:\t+ Loss/regularization_loss: 26.332754\n","I0919 07:37:05.725752 139976889247616 model_lib_v2.py:1010] \t+ Loss/regularization_loss: 26.332754\n","INFO:tensorflow:\t+ Loss/total_loss: 27.420897\n","I0919 07:37:05.726730 139976889247616 model_lib_v2.py:1010] \t+ Loss/total_loss: 27.420897\n","INFO:tensorflow:Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","I0919 07:46:30.480535 139976889247616 checkpoint_utils.py:140] Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","INFO:tensorflow:Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-11\n","I0919 07:46:30.710739 139976889247616 checkpoint_utils.py:149] Found new checkpoint at trained_model/ssd_resnet152_v1_fpn/ckpt-11\n","INFO:tensorflow:Finished eval step 0\n","I0919 07:46:52.175304 139976889247616 model_lib_v2.py:958] Finished eval step 0\n","INFO:tensorflow:Performing evaluation on 65 images.\n","I0919 07:47:06.443639 139976889247616 coco_evaluation.py:293] Performing evaluation on 65 images.\n","creating index...\n","index created!\n","INFO:tensorflow:Loading and preparing annotation results...\n","I0919 07:47:06.444059 139976889247616 coco_tools.py:116] Loading and preparing annotation results...\n","INFO:tensorflow:DONE (t=0.00s)\n","I0919 07:47:06.447599 139976889247616 coco_tools.py:138] DONE (t=0.00s)\n","creating index...\n","index created!\n","Running per image evaluation...\n","Evaluate annotation type *bbox*\n","DONE (t=0.36s).\n","Accumulating evaluation results...\n","DONE (t=0.05s).\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.069\n"," Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.206\n"," Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.019\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.082\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.156\n"," Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.049\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.124\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.279\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.357\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.293\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.371\n"," Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.389\n","INFO:tensorflow:Eval metrics at step 10000\n","I0919 07:47:06.863970 139976889247616 model_lib_v2.py:1007] Eval metrics at step 10000\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.069165\n","I0919 07:47:06.875066 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP: 0.069165\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.206122\n","I0919 07:47:06.876466 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.206122\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.019416\n","I0919 07:47:06.877688 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.019416\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.081710\n","I0919 07:47:06.878894 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (small): 0.081710\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.156114\n","I0919 07:47:06.880137 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (medium): 0.156114\n","INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.049084\n","I0919 07:47:06.881252 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Precision/mAP (large): 0.049084\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.123529\n","I0919 07:47:06.882438 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@1: 0.123529\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.279412\n","I0919 07:47:06.883726 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@10: 0.279412\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.357353\n","I0919 07:47:06.884963 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100: 0.357353\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.292857\n","I0919 07:47:06.886090 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (small): 0.292857\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.371111\n","I0919 07:47:06.887379 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.371111\n","INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.388889\n","I0919 07:47:06.888816 139976889247616 model_lib_v2.py:1010] \t+ DetectionBoxes_Recall/AR@100 (large): 0.388889\n","INFO:tensorflow:\t+ Loss/localization_loss: 0.419826\n","I0919 07:47:06.889841 139976889247616 model_lib_v2.py:1010] \t+ Loss/localization_loss: 0.419826\n","INFO:tensorflow:\t+ Loss/classification_loss: 0.695003\n","I0919 07:47:06.890750 139976889247616 model_lib_v2.py:1010] \t+ Loss/classification_loss: 0.695003\n","INFO:tensorflow:\t+ Loss/regularization_loss: 20.664198\n","I0919 07:47:06.891727 139976889247616 model_lib_v2.py:1010] \t+ Loss/regularization_loss: 20.664198\n","INFO:tensorflow:\t+ Loss/total_loss: 21.779028\n","I0919 07:47:06.892631 139976889247616 model_lib_v2.py:1010] \t+ Loss/total_loss: 21.779028\n","INFO:tensorflow:Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","I0919 07:56:30.779047 139976889247616 checkpoint_utils.py:140] Waiting for new checkpoint at trained_model/ssd_resnet152_v1_fpn/\n","Traceback (most recent call last):\n","  File \"/content/models/research/object_detection/model_main_tf2.py\", line 115, in <module>\n","    tf.compat.v1.app.run()\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 40, in run\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 303, in run\n","    _run_main(main, args)\n","  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 251, in _run_main\n","    sys.exit(main(argv))\n","  File \"/content/models/research/object_detection/model_main_tf2.py\", line 90, in main\n","    wait_interval=600, timeout=FLAGS.eval_timeout)\n","  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1129, in eval_continuously\n","    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 199, in checkpoints_iterator\n","    checkpoint_dir, checkpoint_path, timeout=timeout)\n","  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 147, in wait_for_new_checkpoint\n","    time.sleep(seconds_to_sleep)\n","KeyboardInterrupt\n"]}]},{"cell_type":"code","metadata":{"id":"LqSU-BHigMzX"},"source":[""],"execution_count":null,"outputs":[]}]}